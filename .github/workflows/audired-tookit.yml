name: Audi RED Toolkit

on:
  workflow_call:
    inputs:
        source_file:
            description: 'Source file from the origin directory'
            required: true
            type: string
        destination_repo:
            description: 'Destination repository'
            type: string
            required: false
            default: 'RED-Internal-Development/audi-red-documentation'
        destination_folder:
            description: 'Directory to push the file to'
            type: string
            required: false
        user_email:
            description: 'Email for the git commit'
            type: string
            required: true
        user_name:
            description: 'GitHub username for the commit'
            type: string
            required: true
        user_actor:
            description: 'GitHub username that trigged the pipeline'
            type: string
            required: true
        destination_branch:
            description: 'branch to push file to, defaults to main'
            type: string
            required: false
        destination_branch_create:
            description: 'Destination branch to create for this commit'
            type: string
            required: false
        commit_message:
            description: 'A custom message for the commit'
            type: string
            required: false
        rename:
            description: 'Rename the destination file'
            type: string
            required: false
        use_rsync:
            description: 'Copy files/directories using rsync instead of cp. Experimental feature, please know your use case'
            type: string
            required: false
        git_server:
            description: 'Git server host, default github.com'
            type: string
            required: false
            default: github.com
        msiParentPageIds:
          description: 'By default we deployment all feature apps to a documentation sync parent id in msi. If you prefer to deploy elsewhere in this space, list ids'
          default: ""
          type: string
          required: false
        enable_doc_sync:
            description: 'Enable doc sync step, DOC_SYNC_KEY is required in secrets'
            type: boolean
            required: true
        enable_scanoss:
            description: 'Enable scanoss step, SCANOSS_KEY is required in secrets'
            type: boolean
            required: true
        enable_vwgoa_prod_support_deployment:
            description: 'Enable app deployment to VWGOA Production Support Space'
            type: boolean
            required: false
            default: false
    secrets:
        DOC_SYNC_KEY:
            required: false
            description: 'Team key used to copy files to audired'
        SCANOSS_KEY:
            required: false
            description: 'Key used to authenticate to scanoss for open source checks'

jobs:
    doc_sync:
        runs-on: ubuntu-22.04
        if: ${{ always() && inputs.enable_doc_sync }}
        needs: data_sync
        steps:
          - name: Check if branch exists
            id: check_branch
            shell: bash
            run: |
              BRANCH_NAME="${{ inputs.destination_branch }}"
              DESTINATION_REPO="${{ inputs.destination_repo }}"
              API_URL="https://api.github.com/repos/${DESTINATION_REPO}/branches/${BRANCH_NAME}"

              # Query the GitHub API
              response=$(curl -s -o /dev/null -w "%{http_code}" -H "Authorization: Bearer ${{ secrets.DOC_SYNC_KEY }}" "$API_URL")

              if [ "$response" -eq 200 ]; then
                  echo "Branch '${BRANCH_NAME}' exists."
                  echo "branch_exists=true" >> $GITHUB_OUTPUT
              else
                  echo "Branch '${BRANCH_NAME}' does not exist."
                  echo "branch_exists=false" >> $GITHUB_OUTPUT
              fi

          - name: Checkout
            uses: actions/checkout@v2
          
          - name: Eslint check for Docusaurus build compatibility
            run: |
              cd ${{ inputs.source_file }}
              npx docusaurus-mdx-checker
          
          - name: Install mermaid CLI for parsing
            run: npm install -g @mermaid-js/mermaid-cli
          
          - name: Validate mermaid.js code can be parsed
            run: |
                mkdir -p diagrams
                folder=${{ inputs.source_file }}
                index=1
                find "$folder" -type f \( -name "*.md" -o -name "*.mdx" \) -print0 | while IFS= read -r -d '' file; do
                  echo "Processing markdown file: $file"
                  
                  in_code_block=false
                  mermaid_code=""
                  temp_file=$(mktemp)
                  TMPDIR=$(mktemp -d)

                  while IFS= read -r line; do
                    if [[ "$line" == '```mermaid' ]]; then
                      in_code_block=true
                      mermaid_code=""
                      continue
                    elif [[ "$line" == '```' && "$in_code_block" == true ]]; then
                      echo "Found Mermaid diagram:"
                      echo "$mermaid_code"
                      
                      # Write the Mermaid code to a temporary .mmd file and generate the SVG
                      diagram_name="diagram_${index}.mmd"
                      echo "$mermaid_code" > "diagrams/${diagram_name}"

                      if ! mmdc -i "diagrams/${diagram_name}" -o "$TMPDIR/output_${index}.svg" 2> "$TMPDIR/mmdc_error.log"; then
                        echo "❌ Mermaid validation failed in file:"
                        cat "$TMPDIR/mmdc_error.log"
                        exit 1
                      fi
                      
                      in_code_block=false
                      index=$((index + 1))
                    elif [[ "$in_code_block" == true ]]; then
                      mermaid_code="$mermaid_code$line"$'\n'
                    else
                      echo "$line" >> "$temp_file"
                    fi
                  done < "$file"
                done
                echo "✅ All Mermaid blocks are valid!"

          - name: Check if referenced images exist
            run: |
              find docs/ -type f \( -name "*.md" -o -name "*.mdx" \) -print0 | while IFS= read -r -d '' md_file; do
                    echo "Checking file: $md_file"
                    
                    grep -oP '!\[.*?\]\(\K(.*?)(?=\))' "$md_file" | while read -r image; do
                        image=$(echo "$image" | sed 's/[?#].*$//')
                        if [[ "$image" =~ ^https?:// ]]; then
                            echo "Skipping external image: $image"
                            continue
                        elif [[ "$image" =~ ^/ ]]; then
                            IMAGE_PATH="$GITHUB_WORKSPACE$image"
                        else
                            IMAGE_PATH="$(dirname "$md_file")/$image"
                        fi
    
                        IMAGE_PATH=$(realpath "$IMAGE_PATH")

                        if [[ ! -f "$IMAGE_PATH" ]]; then
                            echo "Image '$image' referenced in '$md_file' does not exist at '$IMAGE_PATH'."
                            exit 1
                        fi
                    done
                done

                echo "All images are properly referenced and exist!"
          
          - name: Download collection report artifact
            if: github.event.workflow_run.id != ''
            uses: actions/download-artifact@v4
            with:
              name: data-report
              path: data-report
              github-token: ${{ github.token }}
              repository: ${{ github.repository }}

          - name: Create or update project metrics with report data
            if: github.event.workflow_run.id != ''
            run: |
              FILE_PATH="${{ inputs.source_file }}/project_metrics.mdx"
              report_file="data-report/report.json"
              report_file_data=$(cat $report_file)

              if [ -z "$report_file_data" ]; then
                  echo "No report results to include, skipping"
              else
                  repo_name=$(echo "$report_file_data" | jq -r 'to_entries | .[0].key')
                  echo "REPO: $repo_name"
                  lighthouse_score=$(jq ".[\"$repo_name\"].lighthouse_score" "$report_file")
                  echo "lighthouse score: $lighthouse_score"
                  unit_test_coverage_data=$(jq ".[\"$repo_name\"].unit_test_coverage" "$report_file")
                  echo "unit test coverage: $unit_test_coverage_data"
                  e2e_test_coverage=$(jq ".[\"$repo_name\"].e2e_test_coverage" "$report_file")
                  echo "e2e test coverage: $e2e_test_coverage"

                  NEW_CONTENT="# CI Report Summary\n"
                  if [ -n "$lighthouse_score" ]  && [ "$lighthouse_score" != "null" ]; then
                    NEW_CONTENT+="- **Lighthouse Score**: $lighthouse_score / 1\n"
                  fi

                  if [ -n "$e2e_test_coverage" ] && [ "$e2e_test_coverage" != "null" ]; then
                    rounded_e2e_test_coverage=$(printf "%.0f" $e2e_test_coverage)
                    NEW_CONTENT+="- **E2E Test Coverage**: $rounded_e2e_test_coverage%\n"
                  fi

                  if [ -n "$unit_test_coverage_data" ] && [ "$unit_test_coverage_data" != "null" ]; then
                    echo "checking unit_test_coverage_data"
                    check_value() {
                      local value=$1
                      value=$(echo "$value" | awk '{print $1+0}')
                      
                      if (( $(echo "$value > 80" | bc -l) )); then
                        echo ":white_check_mark:"
                      elif (( $(echo "$value > 50" | bc -l) )); then
                        echo ":warning:"
                      else
                        echo ":x:"
                      fi
                    }
                    
                    unit_statements=$(jq ".[\"$repo_name\"].unit_test_coverage_data.statement_coverage" "$report_file")
                    unit_functions=$(jq ".[\"$repo_name\"].unit_test_coverage_data.function_coverage" "$report_file")
                    unit_branches=$(jq ".[\"$repo_name\"].unit_test_coverage_data.branch_coverage" "$report_file")
                    unit_lines=$(jq ".[\"$repo_name\"].unit_test_coverage_data.line_coverage" "$report_file")
                    unit_average=$(jq ".[\"$repo_name\"].unit_test_coverage_data.average_coverage" "$report_file")
                    echo "unit_average: $unit_average"
                    rounded_unit_test_coverage=$(printf "%.0f" $unit_average)
                    echo "rounded_unit_test_coverage: $rounded_unit_test_coverage"
                    NEW_CONTENT+=$(
                      echo "## Unit Test Coverage" $'\n' \
                          "| Category | Coverage | Rating |" $'\n' \
                          "|-------------|------------|----------------|" $'\n' \
                          "| Statements | "$unit_statements%" | $(check_value $unit_statements) |" $'\n' \
                          "| Functions  | "$unit_functions%" | $(check_value $unit_functions) |" $'\n' \
                          "| Branches   | "$unit_branches%" | $(check_value $unit_branches) |" $'\n' \
                          "| Lines      | "$unit_lines%" | $(check_value $unit_lines) |" $'\n' \
                          "| Overall    | "$rounded_unit_test_coverage%" | $(check_value $rounded_unit_test_coverage) |" $'\n'
                    )

                    RECOMMENDATIONS_CONTENT=""
                    if (( $(echo "$unit_branches < 60" | bc -l) )); then
                      RECOMMENDATIONS_CONTENT+="- Test more branches (if/else, error handling)"
                    fi

                    if (( $(echo "$unit_functions < 70" | bc -l) )); then
                      RECOMMENDATIONS_CONTENT+="- Write additional unit tests for functions."
                    fi

                    if (( $(echo "$unit_lines < 70" | bc -l) )); then
                      RECOMMENDATIONS_CONTENT+="- Better cover the entire code (e.g. rare code paths)"
                    fi

                    if [[ -n "RECOMMENDATIONS_CONTENT" ]]; then
                      NEW_CONTENT+=$(
                        echo $'\n' "### :pushpin: Recommendations:" $'\n' \
                            "$RECOMMENDATIONS_CONTENT" $'\n'
                      )
                    fi
                  elif [ -n "$unit_test_coverage" ] && [ "$unit_test_coverage" != "null" ]; then
                    rounded_unit_test_coverage=$(printf "%.0f" $unit_test_coverage)
                    NEW_CONTENT+="- **Unit Test Coverage**: $rounded_unit_test_coverage%\n"
                  fi

                  # Check if the file exists
                  if [ -f "$FILE_PATH" ]; then
                    echo "File exists. Appending content to the top of the file: $FILE_PATH"
                    echo -e "$NEW_CONTENT\n$(cat $FILE_PATH)" > $FILE_PATH
                  else
                    echo "File does not exist. Creating a new file: $FILE_PATH"
                    echo -e "$NEW_CONTENT" > $FILE_PATH
                  fi
              fi

          - name: Pushes files from Feature App to Audi RED Portal for syndication
            uses: RED-Internal-Development/audred_docsync_action@main
            env:
              API_TOKEN_GITHUB: ${{ secrets.DOC_SYNC_KEY }}
            with:
              source_file: ${{ inputs.source_file }}
              destination_repo: ${{ inputs.destination_repo }}
              destination_folder: ${{ needs.data_sync.outputs.docs_destination_team_folder }}
              destination_branch: ${{ inputs.destination_branch }}
              user_email: ${{ inputs.user_email }}
              user_name: ${{ inputs.user_name }}
              user_actor: ${{ github.actor }}
              use_rsync: true
              destination_branch_exists: ${{ steps.check_branch.outputs.branch_exists }}

    scanoss:
        runs-on: ubuntu-latest
        if: ${{ inputs.enable_scanoss }}
        steps:
        - name: Checkout
          uses: actions/checkout@v4

        - name: Run SCANOSS Code Scan
          id: scanoss-code-scan-step
          uses: scanoss/gha-code-scan@v0.2.0
          with:
            api.key: ${{ secrets.SCANOSS_KEY }}
            api.url: https://api.scanoss.com/scan/direct
            dependencies.enabled: true
            policies.halt_on_failure: false
            policies: copyleft, undeclared
          
        - name: Upload scanoss report
          if: ${{ steps.scanoss-code-scan-step.outputs.result-filepath }}
          uses: actions/upload-artifact@v4
          with:
            name: scanoss-report
            path: ${{ steps.scanoss-code-scan-step.outputs.result-filepath }}

    data_sync:
        runs-on: ubuntu-latest
        if: always()
        needs: [scanoss, scheduled_sync]
        outputs:
          docs_destination_team_folder: ${{ steps.create-docs-folders.outputs.docs_destination_team_folder }}
        steps:
            - name: Checkout Repository
              uses: actions/checkout@v3

            - name: Collection of metadata from repository
              id: metadata_collection
              uses: RED-Internal-Development/audi-red-app-metadata-kit@staging
              with:
                github_token: ${{ secrets.GITHUB_TOKEN }}
                repository: ${{ github.repository }}
                workflow_run_id: ${{ github.event.workflow_run.id }}
            
            - name: Checkout AudiRed Doc Sync repository
              uses: actions/checkout@v3
              with:
                repository: ${{ inputs.destination_repo }}
                token: ${{ secrets.DOC_SYNC_KEY }}
                ref: doc-sync-queue
            
            - name: Download scanoss report artifact
              if: ${{ inputs.enable_scanoss }}
              uses: actions/download-artifact@v4
              with:
                name: scanoss-report
                path: scanoss-report
            
            - name: Download metadata artifact
              uses: actions/download-artifact@v4
              with:
                name: metadata-report
                path: metadata-report
            
            - name: Download collection report artifact
              if: github.event.workflow_run.id != ''
              uses: actions/download-artifact@v4
              with:
                name: audired-collection-report
                path: collection-report
                github-token: ${{ github.token }}
                repository: ${{ github.repository }}
                run-id: ${{ github.event.workflow_run.id }}
            
            - name: Dynamically create docs destination folder variables
              id: create-docs-folders
              run: |
                app_name=$(basename ${{ inputs.source_file }})
                docs_branch="${{ inputs.destination_branch }}"
                docs_destination_team_folder="docs/feature_apps/${{ inputs.destination_branch }}"
                docs_destination_app_folder="$docs_destination_team_folder/$app_name"

                echo "docs_destination_team_folder=$docs_destination_team_folder" >> $GITHUB_OUTPUT
                echo "docs_branch=$docs_branch" >> $GITHUB_ENV
                echo "docs_destination_team_folder=$docs_destination_team_folder" >> $GITHUB_ENV
                echo "docs_destination_app_folder=$docs_destination_app_folder" >> $GITHUB_ENV

            - name: Update data/report.json with additional metadata
              run: |
                data_folder="data"
                collection_report_file_path="collection-report/report.json"
                metadata_file_path="metadata-report/metadata-report.json"
                output_file_path="combined-data.json"

                metadata_artifact_json=$(cat "$metadata_file_path")
                repo_name=$(echo "$metadata_artifact_json" | jq -r 'to_entries | .[0].key')
      
                if [[ -n "${{ github.event.workflow_run.id }}" ]]; then
                  jq --arg repo_name "$repo_name" \
                    '.[ $repo_name ] |= (. + (input | .[ $repo_name ]))' \
                    "$collection_report_file_path" "$metadata_file_path" > "$output_file_path"

                  report_artifact_json=$(cat $output_file_path)
                else
                  mkdir -p "collection-report"
                  echo $metadata_artifact_json > $collection_report_file_path
                  report_artifact_json=$(cat $collection_report_file_path)
                fi

                echo "report_artifact_json: $report_artifact_json"

                repo_basename=$(basename $repo_name)
                scanoss_results_file_path="scanoss-report/results.json"
                scanoss_enabled=false
                scanoss_target_directory="$data_folder/scanoss"
                scanoss_target_file="$scanoss_target_directory/$repo_basename.json"
                mkdir -p "$scanoss_target_directory"

                if [ -f "$scanoss_results_file_path" ]; then
                    scanoss_enabled=true
                    cp -f "$scanoss_results_file_path" "$scanoss_target_file"
                else
                    echo "No scanoss results to include"
                fi

                timestamp=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

                updated_report_artifact_json=$(echo "$report_artifact_json" | \
                  jq --arg repo_name "$repo_name" \
                  --argjson scan_results "$scanoss_enabled" \
                  --arg docs_destination_team_folder "$docs_destination_team_folder" \
                  --arg docs_destination_app_folder "$docs_destination_app_folder" \
                  --arg docs_branch "$docs_branch" \
                  --arg timestamp "$timestamp" \
                  '.[$repo_name] |= . + {scan_results: $scan_results, docs: {docs_destination_team_folder: $docs_destination_team_folder, docs_destination_app_folder: $docs_destination_app_folder, docs_branch: $docs_branch}, timestamp: $timestamp}')
                echo "$updated_report_artifact_json" > collection-report/report.json
                report_artifact_json=$(cat collection-report/report.json)

                # Push artifact report to existing report.json
                mkdir -p "$data_folder"

                # Check if report.json exists inside the $data_folder folder; if not, create it
                if [ ! -f "$data_folder"/report.json ]; then
                    echo "{}" > "$data_folder"/report.json
                fi

                jq --argjson new_report "$report_artifact_json" \
                  '. * $new_report' "$data_folder"/report.json > tmp_report.json
                
                mv tmp_report.json "$data_folder"/report.json

            - name: Upload final report
              if: github.event.workflow_run.id != ''
              uses: actions/upload-artifact@v4
              with:
                name: data-report
                path: collection-report/report.json
            
            - name: Create Repo Configuration File for MSI/Cloud Deployments
              run: |
                app_name=$(basename ${{ inputs.source_file }})
                team_folder_name=$(basename ${{ inputs.destination_folder }})
                msi_parent_page_ids="${{ inputs.msiParentPageIds }}"
                config_file="deployment/repo_configs/$app_name.json"

                mkdir -p "$(dirname "$config_file")"

                if [[ -z "$msi_parent_page_ids" && "${{ inputs.enable_vwgoa_prod_support_deployment }}" == "false" ]]; then
                  if [[ -f "$config_file" ]]; then
                    rm "$config_file"
                  fi
                else
                  echo '{}' > "$config_file"
                  msi_jq_string=""
                  if [[ -n "$msi_parent_page_ids" ]]; then
                    msi_array=$(echo "$msi_parent_page_ids" | tr ',' '\n' | jq -R . | jq -s .)
                    msi_jq_string=".msi_parent_page_ids = $msi_array | "
                  fi

                  if [ "${{ inputs.enable_vwgoa_prod_support_deployment }}" == "true" ]; then
                    vwgoa_enabled=true
                    vwgoa_jq_string=".vwgoa_enabled = $vwgoa_enabled | "
                  fi
                  
                  jq "$msi_jq_string$vwgoa_jq_string.team_folder = \"$team_folder_name\" | .app_name = \"$app_name\"" "$config_file" > "$config_file.tmp" && mv "$config_file.tmp" "$config_file"
                  echo "config file:"
                  cat "$config_file"
                fi
            
            - name: Commit and push changes
              run: |
                git config --global user.email ${{ inputs.user_email }}
                git config --global user.name ${{ inputs.user_name }}
                git add data/report.json
                if [[ -n "${{ inputs.enable_scanoss }}" ]]; then
                  git add data/scanoss/
                fi
                git add deployment/
                if ! git diff-index --quiet HEAD; then
                    echo "commiting changes"
                    git commit -m "Update report.json and deployment config from ${{ inputs.destination_branch }}"
                    git push
                else
                    echo "No changes to push"
                fi

    scheduled_sync:
      # if: github.event_name == 'schedule'
      runs-on: ubuntu-latest
      steps:
        - name: Checkout Repository
          uses: actions/checkout@v3
        
        - name: Check if test:e2e-run-dev script exists
          id: check_script
          run: |
            if jq -e '.scripts["test:e2e-run-dev"]' package.json > /dev/null; then
              echo "Script exists. Startin cypress install, run, and coverage collection"
              echo "exists=true" >> "$GITHUB_OUTPUT"
            else
              echo "Script does not exist. Skipping cypress collection"
              echo "exists=false" >> "$GITHUB_OUTPUT"
            fi
        
        - name: Load Cypress cache
          if: steps.check_script.outputs.exists == 'true'
          uses: actions/cache@v4.2.0
          with:
            path: |
              ~/.cache/Cypress
            key: ${{ runner.os }}-cypress-${{ hashFiles('**/package-lock.json') }}
            restore-keys: |
              ${{ runner.os }}-cypress

        - name: Setup node
          if: steps.check_script.outputs.exists == 'true'
          uses: actions/setup-node@v4.4.0
          with:
            node-version-file: '.nvmrc'
            cache: npm
            registry-url: https://npm.pkg.github.com

        - name: Install dependencies
          if: steps.check_script.outputs.exists == 'true'
          run: |
            npm ci

        - name: Save node_modules
          if: steps.check_script.outputs.exists == 'true'
          id: cache-node-modules
          uses: actions/cache/save@v4.2.0
          with:
            path: |
              **/node_modules
            key: ${{ runner.os }}-node-modules-cache-${{ github.sha }}
    
        - name: Cypress Coverage Run
          if: steps.check_script.outputs.exists == 'true'
          run: |
            echo "Runs only on a cron job"
            npm run test:e2e-run-dev
        
        - name: E2E (Cypress) Coverage Collection
          if: steps.check_script.outputs.exists == 'true'
          run: |
            if [ -d ".nyc_output" ]; then
                COVERAGE_OUTPUT=$(npx nyc report --reporter=text-summary)

                echo "Coverage Output: $COVERAGE_OUTPUT"

                STATEMENTS=$(echo "$COVERAGE_OUTPUT" | grep -oP 'Statements\s+:\s+\K[0-9.]+|Unknown' | sed 's/Unknown/0/')
                BRANCHES=$(echo "$COVERAGE_OUTPUT" | grep -oP 'Branches\s+:\s+\K[0-9.]+|Unknown' | sed 's/Unknown/0/')
                FUNCTIONS=$(echo "$COVERAGE_OUTPUT" | grep -oP 'Functions\s+:\s+\K[0-9.]+|Unknown' | sed 's/Unknown/0/')
                LINES=$(echo "$COVERAGE_OUTPUT" | grep -oP 'Lines\s+:\s+\K[0-9.]+|Unknown' | sed 's/Unknown/0/')

                echo "Line coverage: $LINES%"
                echo "Statement coverage: $STATEMENTS%"
                echo "Function coverage: $FUNCTIONS%"
                echo "Branch coverage: $BRANCHES%"

                AVERAGE_COVERAGE=$(echo "($LINES + $STATEMENTS + $FUNCTIONS + $BRANCHES) / 4" | bc -l)

                echo "Average coverage: $AVERAGE_COVERAGE%"
            else
                echo ".nyc_output folder does not exist for coverage reporting"
                AVERAGE_COVERAGE=null
            fi

            echo "E2E_TEST_COVERAGE=$AVERAGE_COVERAGE" >> $GITHUB_ENV
            echo "E2E_TEST_COVERAGE_STATEMENTS=$STATEMENTS" >> $GITHUB_ENV
            echo "E2E_TEST_COVERAGE_BRANCHES=$BRANCHES" >> $GITHUB_ENV
            echo "E2E_TEST_COVERAGE_FUNCTIONS=$FUNCTIONS" >> $GITHUB_ENV
            echo "E2E_TEST_COVERAGE_LINES=$LINES" >> $GITHUB_ENV

        - name: Create report.json
          run: |
            echo "{}" > report.json
            report_json=$(cat report.json)

            updated_report=$(echo "$report_json" | jq --arg repo_name "$repo_name" \
                --argjson e2e_test_coverage_statements "$E2E_TEST_COVERAGE_STATEMENTS" \
                --argjson e2e_test_coverage_branches "$E2E_TEST_COVERAGE_BRANCHES" \
                --argjson e2e_test_coverage_functions "$E2E_TEST_COVERAGE_FUNCTIONS" \
                --argjson e2e_test_coverage_lines "$E2E_TEST_COVERAGE_LINES" \
                --argjson e2e_test_coverage "$E2E_TEST_COVERAGE" \
                '. + {($repo_name): {"e2e_test_coverage_breakdown": {"e2e_test_coverage_statements": $e2e_test_coverage_statements, "e2e_test_coverage_branches": $e2e_test_coverage_branches, "e2e_test_coverage_functions": $e2e_test_coverage_functions, "e2e_test_coverage_lines": $e2e_test_coverage_lines}, "e2e_test_coverage": $e2e_test_coverage}}')

            echo "$updated_report" > report.json

        - name: Upload report.json
          uses: actions/upload-artifact@v4.3.1
          with:
            name: audired-cypress-report
            path: report.json